{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import math\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('seaborn')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# To ensure that the code is reproducible, set random seeds\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        token      stemm  pos     annotation          synset  \\\n0      having       have    v  no-annotation       no-synset   \n1         the        the  NaN  no-annotation       no-synset   \n2   necessary  necessary    a     01580050-a  necessary.a.01   \n3       means      means    n     00172710-n      means.n.01   \n4          or         or  NaN  no-annotation       no-synset   \n5       skill      skill    n  no-annotation       no-synset   \n6          or         or  NaN  no-annotation       no-synset   \n7    know-how   know-how    n     05616786-n   know-how.n.01   \n8          or         or  NaN  no-annotation       no-synset   \n9   authority  authority    n     05196582-n  authority.n.01   \n10         to         to  NaN  no-annotation       no-synset   \n11         do         do    v  no-annotation       no-synset   \n12  something  something  NaN  no-annotation       no-synset   \n13        not        not    r     00024073-r        not.r.01   \n14     having       have    v  no-annotation       no-synset   \n15        the        the  NaN  no-annotation       no-synset   \n16  necessary  necessary    a     01580050-a  necessary.a.01   \n17      means      means    n     00172710-n      means.n.01   \n18         or         or  NaN  no-annotation       no-synset   \n19      skill      skill    n  no-annotation       no-synset   \n\n                                     tag  \n0                                      O  \n1                                      O  \n2     [135144.0 25.01 64176.03 90.0 0.5]  \n3      [111736.0 98.31 98012.7 0.0 18.5]  \n4                                      O  \n5                                      O  \n6                                      O  \n7   [142676.0 107.17 71890.08 0.0 106.5]  \n8                                      O  \n9     [37587.0 104.34 194973.98 0.0 7.5]  \n10                                     O  \n11                                     O  \n12                                     O  \n13    [129433.0 178.71 20604.94 0.0 0.5]  \n14                                     O  \n15                                     O  \n16    [135144.0 25.01 64176.03 90.0 0.5]  \n17     [111736.0 98.31 98012.7 0.0 18.5]  \n18                                     O  \n19                                     O  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>stemm</th>\n      <th>pos</th>\n      <th>annotation</th>\n      <th>synset</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>having</td>\n      <td>have</td>\n      <td>v</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the</td>\n      <td>the</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>necessary</td>\n      <td>necessary</td>\n      <td>a</td>\n      <td>01580050-a</td>\n      <td>necessary.a.01</td>\n      <td>[135144.0 25.01 64176.03 90.0 0.5]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>means</td>\n      <td>means</td>\n      <td>n</td>\n      <td>00172710-n</td>\n      <td>means.n.01</td>\n      <td>[111736.0 98.31 98012.7 0.0 18.5]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>skill</td>\n      <td>skill</td>\n      <td>n</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>know-how</td>\n      <td>know-how</td>\n      <td>n</td>\n      <td>05616786-n</td>\n      <td>know-how.n.01</td>\n      <td>[142676.0 107.17 71890.08 0.0 106.5]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>authority</td>\n      <td>authority</td>\n      <td>n</td>\n      <td>05196582-n</td>\n      <td>authority.n.01</td>\n      <td>[37587.0 104.34 194973.98 0.0 7.5]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>to</td>\n      <td>to</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>do</td>\n      <td>do</td>\n      <td>v</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>something</td>\n      <td>something</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>not</td>\n      <td>not</td>\n      <td>r</td>\n      <td>00024073-r</td>\n      <td>not.r.01</td>\n      <td>[129433.0 178.71 20604.94 0.0 0.5]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>having</td>\n      <td>have</td>\n      <td>v</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>the</td>\n      <td>the</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>necessary</td>\n      <td>necessary</td>\n      <td>a</td>\n      <td>01580050-a</td>\n      <td>necessary.a.01</td>\n      <td>[135144.0 25.01 64176.03 90.0 0.5]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>means</td>\n      <td>means</td>\n      <td>n</td>\n      <td>00172710-n</td>\n      <td>means.n.01</td>\n      <td>[111736.0 98.31 98012.7 0.0 18.5]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>skill</td>\n      <td>skill</td>\n      <td>n</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pwngc_path = \"../data/test_transformer/pwngc4torchtext.csv\"\n",
    "pwngc_df = pd.read_csv(pwngc_path, delimiter=\"\\t\", header=None)\n",
    "pwngc_df.columns = [\"token\", \"stemm\", \"pos\", \"annotation\", \"synset\", \"tag\" ]\n",
    "pwngc_df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "532821"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.where(pwngc_df[\"tag\"] != 'O')[0])\n",
    "# 532.821 annotated tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135144.0 25.01 64176.03 90.0 0.5]\n",
      "<class 'str'>\n",
      "tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "tag2 = pwngc_df['tag'][2]\n",
    "print(tag2)\n",
    "print(type(tag2))\n",
    "def removeBra(string_list):\n",
    "    if string_list[0] == \"[\" and string_list[-1] == \"]\":\n",
    "        return string_list[1:-1]\n",
    "    else:\n",
    "        return string_list\n",
    "\n",
    "tag2list = torch.tensor(list(map(float, removeBra(tag2).split(' '))), dtype=torch.float32)\n",
    "# tag2list = ast.literal_eval(tag2)\n",
    "print(tag2list)\n",
    "print(type(tag2list))\n",
    "# type(eval(\"tensor({}, device='{}')\".format(tag2, \"cpu\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# split the dataset into training, validation and testing\n",
    "train_path = \"train.csv\"\n",
    "validate_path = \"validate.csv\"\n",
    "test_path = \"test.csv\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#   train_examples = read_data(\"../data/test_transformer/train.csv\", self.fields) #'data/eng.train.iob', self.fields)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "torchtext.legacy.datasets.sequence_tagging.SequenceTaggingDataset"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(use_vocab=True,\n",
    "                  lower=True)\n",
    "\n",
    "LABEL = data.Field(is_target=True,\n",
    "                   use_vocab=False,\n",
    "                   unk_token=None,\n",
    "                   preprocessing=data.Pipeline(lambda x: torch.tensor(list(map(float, removeBra(x).split(' '))), dtype=torch.double)),\n",
    "                   dtype=data.Pipeline(lambda x: torch.tensor(x, dtype=torch.double)))\n",
    "\n",
    "train, valid, test = datasets.SequenceTaggingDataset.splits(path='../data/test_transformer/',\n",
    "                                   train = train_path,\n",
    "                                   validation = validate_path,\n",
    "                                   test = test_path,\n",
    "                                   fields=[(\"text\",TEXT),(\"lemmatized_text\",TEXT), (None, None), (None,None), (None, None), (\"label\",LABEL)]) #,\n",
    "\n",
    "type(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.datasets.sequence_tagging.SequenceTaggingDataset object at 0x00000164570411C8>\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['having', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how', 'or', 'authority', 'to', 'do', 'something'] ['have', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how', 'or', 'authority', 'to', 'do', 'something'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1174e+05, 9.8310e+01, 9.8013e+04, 0.0000e+00, 1.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4268e+05, 1.0717e+02, 7.1890e+04, 0.0000e+00, 1.0650e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([3.7587e+04, 1.0434e+02, 1.9497e+05, 0.0000e+00, 7.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "13\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['not', 'having', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how'] ['not', 'have', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1174e+05, 9.8310e+01, 9.8013e+04, 0.0000e+00, 1.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4268e+05, 1.0717e+02, 7.1890e+04, 0.0000e+00, 1.0650e+02],\n",
      "       dtype=torch.float64)]\n",
      "9\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['having', 'or', 'being', 'more', 'than', 'normal', 'or', 'necessary', ':'] ['have', 'or', 'be', 'many%3|more%3|much%3|more%4|much%4', 'than', 'normal', 'or', 'necessary', ':'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2872e+05, 2.0550e+01, 5.4535e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "9\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['involving', 'deductive_reasoning', 'from', 'a', 'general', 'principle', 'to', 'a', 'necessary', 'effect'] ['involve', 'deductive_reasoning', 'from', 'a', 'general', 'principle', 'to', 'a', 'necessary', 'effect'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([4.9319e+04, 1.0515e+02, 1.6306e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.1143e+05, 3.0800e+01, 8.3244e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1814e+05, 1.0754e+02, 9.5664e+04, 0.0000e+00, 1.4500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "10\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['not', 'supported', 'by', 'fact'] ['not', 'support', 'by', 'fact'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.4906e+04, 1.0194e+02, 1.1614e+05, 1.8000e+02, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "4\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['not', 'supported', 'by', 'fact'] ['not', 'support', 'by', 'fact'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.4906e+04, 1.0194e+02, 1.1483e+05, 1.8000e+02, 2.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "4\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['lacking', 'necessary', 'physical', 'or', 'mental_ability'] ['lack', 'necessary', 'physical_ability', 'or', 'mental_ability'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([5.1520e+03, 1.1805e+02, 2.2714e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.6015e+04, 1.0743e+02, 1.2885e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "5\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['the', 'necessary', 'consequences', 'of', \"one's\", 'actions'] ['the', 'necessary', 'consequence', 'of', 'one', 'action'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 7.6603e+04, 9.5740e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "6\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['having', 'every', 'necessary', 'or', 'normal', 'part', 'or', 'component', 'or', 'step'] ['have', 'every', 'necessary', 'or', 'normal', 'part', 'or', 'component', 'or', 'step'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2872e+05, 2.0550e+01, 5.4535e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "10\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['having', 'or', 'displaying', 'all', 'the', 'characteristics', 'necessary', 'for', 'completeness'] ['have', 'or', 'display', 'all', 'the', 'characteristic', 'necessary', 'for', 'completeness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.0349e+04, 1.0389e+02, 1.6340e+05, 0.0000e+00, 2.4500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.6165e+04, 1.1673e+02, 2.1134e+05, 0.0000e+00, 3.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "9\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['having', 'or', 'displaying', 'all', 'the', 'characteristics', 'necessary', 'for', 'completeness'] ['have', 'or', 'display', 'all', 'the', 'characteristic', 'necessary', 'for', 'completeness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.0349e+04, 1.0389e+02, 1.8358e+05, 0.0000e+00, 3.9500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.6165e+04, 1.1673e+02, 2.1134e+05, 0.0000e+00, 3.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "9\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['(', 'of', 'a', 'boat', 'or', 'vessel', ')', 'furnished', 'with', 'necessary', 'official_documents', 'specifying', 'ownership', 'etc'] ['(', 'of', 'a', 'boat', 'or', 'vessel', ')', 'furnished', 'with', 'necessary', 'official_document', 'specify', 'ownership', 'etc.'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([3.4035e+04, 7.8060e+01, 1.7478e+05, 0.0000e+00, 6.4500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.9658e+04, 7.3010e+01, 1.3975e+05, 0.0000e+00, 1.8950e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([7.7181e+04, 1.1327e+02, 1.4597e+05, 0.0000e+00, 2.8850e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.2580e+03, 1.0677e+02, 2.2125e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.7896e+04, 1.7910e+02, 6.2122e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "14\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['lacking', 'necessary', 'documents', '(', 'as', 'for', 'e.g.', 'permission', 'to', 'live', 'or', 'work', 'in', 'a', 'country', ')'] ['lack', 'necessary', 'document', '(', 'as', 'for', 'e.g.', 'permission', 'to', 'live', 'or', 'work', 'in', 'a', 'country', ')'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([6.4798e+04, 1.0888e+02, 1.5864e+05, 0.0000e+00, 3.9050e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.6105e+04, 1.7943e+02, 8.3903e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.5885e+04, 1.0822e+02, 1.6395e+05, 0.0000e+00, 1.3500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4370e+03, 9.3970e+01, 2.0489e+05, 0.0000e+00, 2.2750e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "16\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['lacking', 'necessary', 'force', 'for', 'effectiveness'] ['lack', 'necessary', 'force', 'for', 'effectiveness'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3004e+05, 1.1761e+02, 1.0131e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "5\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['using', 'the', 'minimum', 'of', 'time', 'or', 'resources', 'necessary', 'for', 'effectiveness'] ['use', 'the', 'minimum', 'of', 'time', 'or', 'resource', 'necessary', 'for', 'effectiveness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.8864e+04, 7.5350e+01, 1.4785e+05, 5.3130e+01, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.8408e+04, 1.0795e+02, 1.8866e+05, 0.0000e+00, 1.2500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3004e+05, 1.1761e+02, 1.0131e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "10\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['possible', 'but', 'not', 'necessary'] ['possible', 'but', 'not', 'necessary'] [tensor([8.5479e+04, 6.0380e+01, 1.2985e+05, 9.5740e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "4\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['left', 'to', 'personal', 'choice'] ['leave', 'to', 'personal', 'choice'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([2.7140e+04, 1.9770e+01, 1.2471e+05, 2.5840e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.4028e+05, 7.7850e+01, 1.0613e+05, 6.0000e+01, 5.9500e+01],\n",
      "       dtype=torch.float64)]\n",
      "4\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['morally', 'binding', 'or', 'necessary'] ['morally', 'bind', 'or', 'necessary'] [tensor([2.4772e+04, 1.7990e+02, 1.2524e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "4\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['urgently', 'needed'] ['urgently', 'need'] [tensor([2.6208e+04, 1.7894e+02, 1.2382e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.9570e+03, 1.0177e+02, 7.9864e+04, 1.8000e+02, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "2\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['absolutely', 'necessary'] ['absolutely', 'necessary'] [tensor([8.1604e+04, 1.7865e+02, 6.8438e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "2\n",
      "<class 'list'> <class 'list'> <class 'list'>\n",
      "['fitted', 'or', 'equipped', 'with', 'necessary', 'rigging', '(', 'sails', 'and', 'shrouds', 'and', 'stays', 'etc', ')'] ['fit', 'or', 'equip', 'with', 'necessary', 'rigging', '(', 'sail', 'and', 'shroud', 'and', 'stays', 'etc.', ')'] [tensor([1.2442e+05, 4.6020e+01, 1.8016e+05, 1.8000e+02, 2.6500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4270e+05, 9.0190e+01, 7.2764e+04, 1.8000e+02, 2.6500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.7251e+04, 8.1770e+01, 1.2355e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.9339e+04, 7.0330e+01, 1.5216e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.7896e+04, 1.7910e+02, 6.2122e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for t, lt, l in zip(train.text, train.lemmatized_text, train.label):\n",
    "    print(type(l), type(lt), type(l))\n",
    "    print(t, lt, l)\n",
    "    print(len(t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "9\n",
      "9\n",
      "10\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "10\n",
      "9\n",
      "9\n",
      "14\n",
      "16\n",
      "5\n",
      "10\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for ex in train:\n",
    "    print(len(ex.text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using pre-trained word embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained embeddings that come with the torchtext library.\n",
    "use_pretrained = True\n",
    "if use_pretrained:\n",
    "    print('We are using pre-trained word embeddings.')\n",
    "    TEXT.build_vocab(train, vectors=\"glove.840B.300d\")\n",
    "else:\n",
    "    print('We are training word embeddings from scratch.')\n",
    "    TEXT.build_vocab(train, max_size=5000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torchtext.legacy.data.example.Example object at 0x000001F436560848>, <torchtext.legacy.data.example.Example object at 0x000001F4365507C8>, <torchtext.legacy.data.example.Example object at 0x000001F436550BC8>, <torchtext.legacy.data.example.Example object at 0x000001F436550F88>, <torchtext.legacy.data.example.Example object at 0x000001F436550408>, <torchtext.legacy.data.example.Example object at 0x000001F436550308>, <torchtext.legacy.data.example.Example object at 0x000001F436550908>, <torchtext.legacy.data.example.Example object at 0x000001F436798808>, <torchtext.legacy.data.example.Example object at 0x000001F436550188>, <torchtext.legacy.data.example.Example object at 0x000001F436550AC8>, <torchtext.legacy.data.example.Example object at 0x000001F436550688>, <torchtext.legacy.data.example.Example object at 0x000001F43653ACC8>, <torchtext.legacy.data.example.Example object at 0x000001F4365348C8>, <torchtext.legacy.data.example.Example object at 0x000001F436798248>, <torchtext.legacy.data.example.Example object at 0x000001F436790FC8>, <torchtext.legacy.data.example.Example object at 0x000001F436798B88>, <torchtext.legacy.data.example.Example object at 0x000001F4367988C8>, <torchtext.legacy.data.example.Example object at 0x000001F43654DE48>, <torchtext.legacy.data.example.Example object at 0x000001F4365505C8>, <torchtext.legacy.data.example.Example object at 0x000001F436550B48>, <torchtext.legacy.data.example.Example object at 0x000001F436540648>]\n"
     ]
    }
   ],
   "source": [
    "# for key, val in zip(TEXT.vocab.stoi, TEXT.vocab.vectors):\n",
    "    # print(key, val)\n",
    "\n",
    "print(list(train))\n",
    "# print(TEXT.vocab.stoi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# b= data.example.Example.fromlist([train.text, train.label], fields=[(\"text\",TEXT),(\"lemmatized_text\",TEXT), (None, None), (None,None), (None, None), (\"label\",LABEL)])\n",
    "# TEXT.build_vocab(b, vectors=\"glove.840B.300d\")\n",
    "# print(b.vocab)\n",
    "# for tt in b:\n",
    "#     print(tt.vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # sort=False, # to skip sorting validation and testing data\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    repeat=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('or', 36), ('necessary', 34), ('the', 12), ('for', 10), ('to', 8), ('not', 8), ('a', 8), ('having', 6), ('of', 6), ('(', 6)]\n",
      "----------------------------------------\n",
      "['<unk>', '<pad>', 'or', 'necessary', 'the', 'for', 'a', 'not', 'to', '(']\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x0000016457039FC8>>, {'<unk>': 0, '<pad>': 1, 'or': 2, 'necessary': 3, 'the': 4, 'for': 5, 'a': 6, 'not': 7, 'to': 8, '(': 9, ')': 10, 'have': 11, 'having': 12, 'of': 13, 'all': 14, 'and': 15, 'by': 16, 'completeness': 17, 'effectiveness': 18, 'fact': 19, 'know-how': 20, 'means': 21, 'normal': 22, 'skill': 23, 'with': 24, 'lack': 25, 'lacking': 26, ':': 27, 'absolutely': 28, 'as': 29, 'authority': 30, 'boat': 31, 'but': 32, 'characteristic': 33, 'characteristics': 34, 'choice': 35, 'component': 36, 'country': 37, 'deductive_reasoning': 38, 'display': 39, 'displaying': 40, 'do': 41, 'e.g.': 42, 'effect': 43, 'etc': 44, 'etc.': 45, 'every': 46, 'force': 47, 'from': 48, 'furnished': 49, 'general': 50, 'in': 51, 'live': 52, 'mental_ability': 53, 'minimum': 54, 'morally': 55, 'ownership': 56, 'part': 57, 'permission': 58, 'personal': 59, 'possible': 60, 'principle': 61, 'rigging': 62, 'something': 63, 'stays': 64, 'step': 65, 'support': 66, 'supported': 67, 'than': 68, 'time': 69, 'urgently': 70, 'vessel': 71, 'work': 72, 'action': 73, 'actions': 74, 'be': 75, 'being': 76, 'bind': 77, 'binding': 78, 'consequence': 79, 'consequences': 80, 'document': 81, 'documents': 82, 'equip': 83, 'equipped': 84, 'fit': 85, 'fitted': 86, 'involve': 87, 'involving': 88, 'leave': 89, 'left': 90, 'many%3|more%3|much%3|more%4|much%4': 91, 'more': 92, 'need': 93, 'needed': 94, 'official_document': 95, 'official_documents': 96, 'one': 97, \"one's\": 98, 'physical': 99, 'physical_ability': 100, 'resource': 101, 'resources': 102, 'sail': 103, 'sails': 104, 'shroud': 105, 'shrouds': 106, 'specify': 107, 'specifying': 108, 'use': 109, 'using': 110})\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2285,  0.1390, -0.3711,  ..., -0.4301,  0.3176,  0.1462],\n",
      "        ...,\n",
      "        [ 0.7643, -0.1219, -0.4445,  ..., -0.0662,  0.1672, -0.1221],\n",
      "        [-0.0396, -0.0633, -0.2984,  ..., -0.3138,  0.1877,  0.7522],\n",
      "        [-0.3028, -0.2062, -0.4449,  ...,  0.0343, -0.1118,  0.9082]])\n"
     ]
    }
   ],
   "source": [
    "# print(train_iterator.data())\n",
    "\n",
    "train_batch = train_iterator.data()\n",
    "print(TEXT.vocab.freqs.most_common(10))\n",
    "print(\"-\"*40)\n",
    "print(TEXT.vocab.itos[:10])\n",
    "print(TEXT.vocab.stoi)\n",
    "print(TEXT.vocab.vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified Field dtype <torchtext.legacy.data.pipeline.Pipeline object at 0x0000016457041248> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19268/3258596146.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mbat\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_iterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# for batch in train_iterator:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m#     print(type(batch))#, type(batch.text), type(batch.label))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;31m# print(batch.text[0], type(batch.text[0]))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\iterator.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    158\u001B[0m                     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m                         \u001B[0mminibatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort_key\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreverse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m                 \u001B[1;32myield\u001B[0m \u001B[0mBatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mminibatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, dataset, device)\u001B[0m\n\u001B[0;32m     32\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mfield\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m                     \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m                     \u001B[0msetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mprocess\u001B[1;34m(self, batch, device)\u001B[0m\n\u001B[0;32m    229\u001B[0m         \"\"\"\n\u001B[0;32m    230\u001B[0m         \u001B[0mpadded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m         \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumericalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpadded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mnumericalize\u001B[1;34m(self, arr, device)\u001B[0m\n\u001B[0;32m    340\u001B[0m                     \u001B[1;34m\"use_vocab=False because we do not know how to numericalize it. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m                     \u001B[1;34m\"Please raise an issue at \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 342\u001B[1;33m                     \"https://github.com/pytorch/text/issues\".format(self.dtype))\n\u001B[0m\u001B[0;32m    343\u001B[0m             \u001B[0mnumericalization_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;31m# It doesn't make sense to explicitly coerce to a numeric type if\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Specified Field dtype <torchtext.legacy.data.pipeline.Pipeline object at 0x0000016457041248> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues"
     ]
    }
   ],
   "source": [
    "for bat in train_iterator:\n",
    "    print(bat)\n",
    "# for batch in train_iterator:\n",
    "#     print(type(batch))#, type(batch.text), type(batch.label))\n",
    "    # print(batch.text[0], type(batch.text[0]))\n",
    "    # print(batch.text, batch.lemmatized_text, batch.label)\n",
    "\n",
    "\n",
    "\n",
    "# for batch in train_iterator.data():\n",
    "#     print(type(batch), type(batch.text), type(batch.label))\n",
    "#     print(batch.text[0], type(batch.text[0]))\n",
    "#     print(batch.text, batch.lemmatized_text, batch.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[<torchtext.legacy.data.example.Example at 0x16456f6f8c8>,\n <torchtext.legacy.data.example.Example at 0x16457042e48>,\n <torchtext.legacy.data.example.Example at 0x1645701d488>,\n <torchtext.legacy.data.example.Example at 0x1645701d848>,\n <torchtext.legacy.data.example.Example at 0x16457035788>,\n <torchtext.legacy.data.example.Example at 0x1645701d288>,\n <torchtext.legacy.data.example.Example at 0x1645703b448>,\n <torchtext.legacy.data.example.Example at 0x1645701d788>,\n <torchtext.legacy.data.example.Example at 0x16457042c48>,\n <torchtext.legacy.data.example.Example at 0x16457042e08>,\n <torchtext.legacy.data.example.Example at 0x1645701d5c8>,\n <torchtext.legacy.data.example.Example at 0x1645701d9c8>,\n <torchtext.legacy.data.example.Example at 0x164570425c8>,\n <torchtext.legacy.data.example.Example at 0x1645701dac8>,\n <torchtext.legacy.data.example.Example at 0x1645701d808>,\n <torchtext.legacy.data.example.Example at 0x164570424c8>,\n <torchtext.legacy.data.example.Example at 0x16457042508>,\n <torchtext.legacy.data.example.Example at 0x1645703ae88>,\n <torchtext.legacy.data.example.Example at 0x16457042b48>,\n <torchtext.legacy.data.example.Example at 0x1645703ab88>,\n <torchtext.legacy.data.example.Example at 0x1645701d588>]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_iterator.data())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "train_batches = list(train_iterator.data())\n",
    "valid_batches = list(valid_iterator.data())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class TransformerEncoderModel(nn.Module):\n",
    "\n",
    "    def __init__(self, text_field, label_field, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        # Multi-head attention mechanism is included in TransformerEncoderLayer\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        # self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "        # -------------------------------------\n",
    "\n",
    "        voc_size = len(text_field.vocab)\n",
    "        print(\"voc_size: \", voc_size )\n",
    "\n",
    "        # Embedding layer. If we're using pre-trained embeddings, copy them\n",
    "        # into our embedding module.\n",
    "        self.embedding = nn.Embedding(voc_size, 300)\n",
    "        print(\"Embedding\", self.embedding)\n",
    "        if text_field.vocab.vectors is not None:\n",
    "            self.embedding.weight = torch.nn.Parameter(TEXT.vocab.vectors)\n",
    "\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        # self.decoder.bias.data.zero_()\n",
    "        # self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = torch.tensor(src, device=\"cpu\")\n",
    "        src = self.embedding(src)\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src) #, src_mask)\n",
    "        # output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "#     \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "#     return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# train_batches = train_iterator.data()\n",
    "# for batch in train_batches:\n",
    "#     print(batch)\n",
    "#     # batch.text is of shape: (input_data_length, batch_size)\n",
    "#     print(batch.text)\n",
    "#     # print(batch.text.vocab)\n",
    "#     # print(batch.text.vocab.vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using pre-trained word embeddings.\n",
      "voc_size:  2\n",
      "Embedding Embedding(2, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Specified Field dtype <torchtext.legacy.data.pipeline.Pipeline object at 0x0000016457041248> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19268/2898834927.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    251\u001B[0m \u001B[0mtagger\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTagger\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 252\u001B[1;33m \u001B[0mtagger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19268/2898834927.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    181\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m             \u001B[1;31m# For each batch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 183\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mbatch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_batches\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    184\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    185\u001B[0m                 \u001B[1;31m# Compute the output and loss.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\iterator.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    158\u001B[0m                     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m                         \u001B[0mminibatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort_key\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreverse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m                 \u001B[1;32myield\u001B[0m \u001B[0mBatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mminibatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, dataset, device)\u001B[0m\n\u001B[0;32m     32\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mfield\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m                     \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m                     \u001B[0msetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mprocess\u001B[1;34m(self, batch, device)\u001B[0m\n\u001B[0;32m    229\u001B[0m         \"\"\"\n\u001B[0;32m    230\u001B[0m         \u001B[0mpadded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m         \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumericalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpadded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mnumericalize\u001B[1;34m(self, arr, device)\u001B[0m\n\u001B[0;32m    340\u001B[0m                     \u001B[1;34m\"use_vocab=False because we do not know how to numericalize it. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m                     \u001B[1;34m\"Please raise an issue at \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 342\u001B[1;33m                     \"https://github.com/pytorch/text/issues\".format(self.dtype))\n\u001B[0m\u001B[0;32m    343\u001B[0m             \u001B[0mnumericalization_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;31m# It doesn't make sense to explicitly coerce to a numeric type if\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Specified Field dtype <torchtext.legacy.data.pipeline.Pipeline object at 0x0000016457041248> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues"
     ]
    }
   ],
   "source": [
    "class Tagger:\n",
    "\n",
    "    def __init__(self, lower):\n",
    "        self.TEXT = data.Field(use_vocab=True,\n",
    "                  lower=True)\n",
    "\n",
    "        self.LABEL = data.Field(is_target=True,\n",
    "                           use_vocab=False,\n",
    "                           unk_token=None,\n",
    "                           preprocessing=data.Pipeline(\n",
    "                               lambda x: torch.tensor(list(map(float, removeBra(x).split(' '))),\n",
    "                                                      dtype=torch.double)),\n",
    "                           dtype=torch.DoubleTensor)\n",
    "                                #data.Pipeline(lambda x: torch.tensor(x, dtype=torch.double)))\n",
    "\n",
    "        self.fields = [(\"text\",self.TEXT),(\"lemmatized_text\",self.TEXT), (None, None), (None,None), (None, None), (\"label\",LABEL)]\n",
    "\n",
    "\n",
    "        # self.TEXT = data.Field(init_token='<bos>', eos_token='<eos>', sequential=True, lower=lower)\n",
    "        # I changed sequential = True to false, because my data is not sequential\n",
    "        # self.LABEL = data.Field(init_token='<bos>', eos_token='<eos>', sequential=True, unk_token=None)\n",
    "        # self.LABEL = data.Field(is_target=True, sequential=False, unk_token=None, dtype=list)\n",
    "        # data.Field(init_token='<bos>', eos_token='<eos>',\n",
    "        #     sequential=False, use_vocab=False)\n",
    "        # self.fields = [('text', self.TEXT), ('label', self.LABEL)]\n",
    "        # self.device = 'cuda'\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    def tag(self, sentences):\n",
    "        # This method applies the trained model to a list of sentences.\n",
    "\n",
    "        # First, create a torchtext Dataset containing the sentences to tag.\n",
    "        examples = []\n",
    "        for sen in sentences:\n",
    "            labels = ['?']*len(sen) # placeholder\n",
    "            examples.append(data.Example.fromlist([sen, labels], self.fields))\n",
    "        dataset = data.Dataset(examples, self.fields)\n",
    "\n",
    "        iterator = data.Iterator(\n",
    "            dataset,\n",
    "            device=self.device,\n",
    "            batch_size= 5, #64,\n",
    "            repeat=False,\n",
    "            train=False,\n",
    "            sort=False)\n",
    "\n",
    "        # Apply the trained model to all batches.\n",
    "        out = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterator:\n",
    "                # Call the model's predict method. This returns a list of NumPy matrix\n",
    "                # containing the integer-encoded tags for each sentence.\n",
    "                predicted = self.model.predict(batch.text)\n",
    "\n",
    "                # # Convert the integer-encoded tags to tag strings.\n",
    "                # for tokens, pred_sen in zip(sentences, predicted):\n",
    "                #     out.append([self.LABEL.vocab.itos[pred_id] for _, pred_id in zip(tokens, pred_sen[1:])])\n",
    "        return predicted #out\n",
    "\n",
    "    def train(self):\n",
    "        # Read training and validation data according to the predefined split.\n",
    "        # train_examples = read_data(\"../data/test_transformer/train.csv\", self.fields) #'data/eng.train.iob', self.fields)\n",
    "        # valid_examples = read_data(\"../data/test_transformer/validate.csv\", self.fields) #'data/eng.valid.iob', self.fields)\n",
    "\n",
    "        train_examples, valid_examples, test_examples = datasets.SequenceTaggingDataset.splits(path='../data/test_transformer/',\n",
    "                                           train = train_path,\n",
    "                                           validation = validate_path,\n",
    "                                           test = test_path,\n",
    "                                           fields=[(\"text\",TEXT),(\"lemmatized_text\",TEXT), (None, None), (None,None), (None, None), (\"label\",LABEL)]) #,\n",
    "\n",
    "\n",
    "        # Count the number of words and sentences.\n",
    "        n_tokens_train = 0\n",
    "        n_sentences_train = 0\n",
    "        for ex in train_examples:\n",
    "            n_tokens_train += len(ex.text) #+ 2\n",
    "            n_sentences_train += 1\n",
    "        n_tokens_valid = 0\n",
    "        for ex in valid_examples:\n",
    "            n_tokens_valid += len(ex.text)\n",
    "\n",
    "        # Load the pre-trained embeddings that come with the torchtext library.\n",
    "        use_pretrained = True\n",
    "        if use_pretrained:\n",
    "            print('We are using pre-trained word embeddings.')\n",
    "            self.TEXT.build_vocab(train_examples, vectors=\"glove.840B.300d\")\n",
    "        else:\n",
    "            print('We are training word embeddings from scratch.')\n",
    "            self.TEXT.build_vocab(train_examples, max_size=5000)\n",
    "        # self.LABEL.build_vocab(train_examples)\n",
    "\n",
    "        # Create one of the models defined above.\n",
    "        # self.model = RNNTagger(self.TEXT, self.LABEL, emb_dim=300, rnn_size=128, update_pretrained=False)\n",
    "        # self.model = RNNCRFTagger(self.TEXT, self.LABEL, emb_dim=300, rnn_size=128, update_pretrained=False)\n",
    "\n",
    "        self.model = TransformerEncoderModel(text_field=self.TEXT,\n",
    "                                             label_field=self.LABEL,\n",
    "                                             ntoken=300,\n",
    "                                             d_model=300,\n",
    "                                             d_hid=200,\n",
    "                                             nlayers=2,\n",
    "                                             nhead=2,\n",
    "                                             dropout=0.2)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # -----------------------------------------------------------\n",
    "        #                       BucketIterator\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        batch_size = 5 #1024\n",
    "        n_batches = np.ceil(n_sentences_train / batch_size)\n",
    "\n",
    "        mean_n_tokens = n_tokens_train / n_batches\n",
    "\n",
    "        train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "                                                        (train_examples, valid_examples, test_examples),\n",
    "                                                        device=self.device,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        sort_key=lambda x: len(x.text),\n",
    "                                                        repeat=False,\n",
    "                                                        sort=True)\n",
    "\n",
    "        # train_iterator = data.BucketIterator(\n",
    "        #     train_examples,\n",
    "        #     device=self.device,\n",
    "        #     batch_size=batch_size,\n",
    "        #     sort_key=lambda x: len(x.text),\n",
    "        #     repeat=False,\n",
    "        #     train=True,\n",
    "        #     sort=True)\n",
    "        #\n",
    "        # valid_iterator = data.BucketIterator(\n",
    "        #     valid_examples,\n",
    "        #     device=self.device,\n",
    "        #     batch_size= 2, #64,\n",
    "        #     sort_key=lambda x: len(x.text),\n",
    "        #     repeat=False,\n",
    "        #     train=False,\n",
    "        #     sort=True)\n",
    "\n",
    "        train_batches = train_iterator\n",
    "        valid_batches = valid_iterator\n",
    "        test_batches = valid_iterator\n",
    "\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        #                       Optimizer\n",
    "        # ---------------------------------------------------------------------\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        lr = 5.0  # learning rate\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "        # -------\n",
    "\n",
    "\n",
    "        # optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "        # n_labels = len(self.LABEL.vocab)\n",
    "\n",
    "        # ----------------------------------------------------------\n",
    "        #                       Epoch Training\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "        history = defaultdict(list)\n",
    "\n",
    "        n_epochs = 3 #25\n",
    "\n",
    "        # For each epoch\n",
    "        for i in range(1, n_epochs + 1):\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            loss_sum = 0\n",
    "\n",
    "            self.model.train()\n",
    "\n",
    "            # for transformer\n",
    "            scheduler.step()\n",
    "\n",
    "            # For each batch\n",
    "            for batch in train_batches:\n",
    "\n",
    "                # Compute the output and loss.\n",
    "                # loss = self.model(batch.text, batch.label) / mean_n_tokens\n",
    "\n",
    "                out = self.model(batch.text)\n",
    "                ntokens = 300\n",
    "                loss = criterion(out.view(-1, ntokens), batch.label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # I added this\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
    "                # ---\n",
    "                optimizer.step()\n",
    "                loss_sum += loss.item()\n",
    "\n",
    "\n",
    "            train_loss = loss_sum / n_batches\n",
    "            history['train_loss'].append(train_loss)\n",
    "\n",
    "            # Evaluate on the validation set.\n",
    "            if i % 1 == 0:\n",
    "\n",
    "                stats = defaultdict(Counter)\n",
    "\n",
    "                # from transformers\n",
    "                # lr = scheduler.get_last_lr()[0]\n",
    "                # ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "                # cur_loss = total_loss / log_interval\n",
    "                # ppl = math.exp(cur_loss)\n",
    "                # print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                #       f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                #       f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "                # total_loss = 0\n",
    "\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for batch in valid_batches:\n",
    "                        # Predict the model's output on a batch.\n",
    "                        predicted = self.model.predict(batch.text)\n",
    "                        print(\"predicted := \", predicted)\n",
    "                        # Update the evaluation statistics.\n",
    "                        # evaluate_iob(predicted, batch.label, self.LABEL, stats)\n",
    "\n",
    "                # # Compute the overall F-score for the validation set.\n",
    "                # _, _, val_f1 = prf(stats['total'])\n",
    "                #\n",
    "                # history['val_f1'].append(val_f1)\n",
    "                #\n",
    "                # t1 = time.time()\n",
    "                # print(f'Epoch {i}: train loss = {train_loss:.4f}, val f1: {val_f1:.4f}, time = {t1-t0:.4f}')\n",
    "\n",
    "        # # After the final evaluation, we print more detailed evaluation statistics, including\n",
    "        # # precision, recall, and F-scores for the different types of named entities.\n",
    "        # print()\n",
    "        # print('Final evaluation on the validation set:')\n",
    "        # p, r, f1 = prf(stats['total'])\n",
    "        # print(f'Overall: P = {p:.4f}, R = {r:.4f}, F1 = {f1:.4f}')\n",
    "        # for label in stats:\n",
    "        #     if label != 'total':\n",
    "        #         p, r, f1 = prf(stats[label])\n",
    "        #         print(f'{label:4s}: P = {p:.4f}, R = {r:.4f}, F1 = {f1:.4f}')\n",
    "        #\n",
    "        # plt.plot(history['train_loss'])\n",
    "        # plt.plot(history['val_f1'])\n",
    "        # plt.legend(['training loss', 'validation F-score'])\n",
    "\n",
    "tagger = Tagger(lower=False)\n",
    "tagger.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using pre-trained word embeddings.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Specified Field dtype <torchtext.legacy.data.pipeline.Pipeline object at 0x0000016457041248> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19268/1677903706.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     30\u001B[0m                                                         sort=True)\n\u001B[0;32m     31\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_iterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Numericalize premises:\\n\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Entailment labels:\\n\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\iterator.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    158\u001B[0m                     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m                         \u001B[0mminibatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort_key\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreverse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m                 \u001B[1;32myield\u001B[0m \u001B[0mBatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mminibatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, dataset, device)\u001B[0m\n\u001B[0;32m     32\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mfield\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m                     \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m                     \u001B[0msetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mprocess\u001B[1;34m(self, batch, device)\u001B[0m\n\u001B[0;32m    229\u001B[0m         \"\"\"\n\u001B[0;32m    230\u001B[0m         \u001B[0mpadded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m         \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumericalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpadded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mnumericalize\u001B[1;34m(self, arr, device)\u001B[0m\n\u001B[0;32m    340\u001B[0m                     \u001B[1;34m\"use_vocab=False because we do not know how to numericalize it. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m                     \u001B[1;34m\"Please raise an issue at \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 342\u001B[1;33m                     \"https://github.com/pytorch/text/issues\".format(self.dtype))\n\u001B[0m\u001B[0;32m    343\u001B[0m             \u001B[0mnumericalization_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;31m# It doesn't make sense to explicitly coerce to a numeric type if\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Specified Field dtype <torchtext.legacy.data.pipeline.Pipeline object at 0x0000016457041248> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues"
     ]
    }
   ],
   "source": [
    "def decode_params(spatial_params):\n",
    "    l0 = spatial_params[0]\n",
    "    alpha = spatial_params[1]\n",
    "    alpha_rad = alpha * np.pi / 180\n",
    "    l_i = spatial_params[2]\n",
    "    beta_i = spatial_params[3]\n",
    "    beta_i_rad = beta_i * np.pi / 180\n",
    "    r = spatial_params[4]\n",
    "    return l0, alpha, alpha_rad, l_i, beta_i, beta_i_rad, r\n",
    "\n",
    "\n",
    "def point_in_space(spatial_params):\n",
    "    l0, alpha, alpha_rad, l_i, beta_i, beta_i_rad, r = decode_params(spatial_params)\n",
    "    # np.cos() and np.sin() take angles in radian as params\n",
    "    center_pt = np.array([l0*np.cos(alpha_rad), l0 * np.sin(alpha_rad)])\n",
    "    sense_pt = center_pt + np.array([l_i * np.cos(alpha_rad + beta_i_rad),\n",
    "                                     l_i * np.sin(alpha_rad + beta_i_rad)])\n",
    "    return sense_pt, center_pt\n",
    "\n",
    "\n",
    "def inside_sphere(point, sphere_coo):\n",
    "\n",
    "    pt = point_in_space(point)\n",
    "    sphere_sense, sphere_center = point_in_space(sphere_coo)\n",
    "\n",
    "    sphere_rad = sphere_coo[-1] # in angles\n",
    "\n",
    "    contained = (pt[0] - sphere_sense[0])**2 + (pt[1] - sphere_sense[1])**2 <= sphere_rad**2\n",
    "\n",
    "    if contained:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def distance(pred_pt, original_pt):\n",
    "    \"\"\"\n",
    "    Calculates the distance between two sense points.\n",
    "    :param pred_pt:\n",
    "    :param original_pt:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pred_sense, pred_center = point_in_space(pred_pt)\n",
    "    orig_sense, orig_center = point_in_space(original_pt)\n",
    "\n",
    "    return np.linalg.norm(pred_sense - orig_sense)\n",
    "\n",
    "\n",
    "\n",
    "def sphere_dist(pred_pt, original_pt):\n",
    "    \"\"\"\n",
    "    Calculates the distance between two 2D spheres.\n",
    "    :param pred_pt:\n",
    "    :param original_pt:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pred_sense, pred_center = point_in_space(pred_pt)\n",
    "    pred_radius = pred_pt[-1]\n",
    "    orig_sense, orig_center = point_in_space(original_pt)\n",
    "    orig_radius = original_pt[-1]\n",
    "\n",
    "    return (pred_radius + orig_radius -\n",
    "            np.linalg.norm(pred_sense - orig_sense))\n",
    "\n",
    "def decode_prediction(spatial_params, df=\"SPATIAL_WORDNET.pickle\") -> [str]:\n",
    "    \"\"\"\n",
    "    Projects the predicted spatial parameters into the embedding space.\n",
    "    Returns the synsets in the vacinity of the projected point.\n",
    "    :param spatial_params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    synsets = [] # sort from specific to most general\n",
    "\n",
    "    sense_pt, center_pt = point_in_space(spatial_params)\n",
    "\n",
    "    spatial_df = pd.read_pickle(df)\n",
    "    # get the spheres, where the point/point+radius is contained/overlaping/near\n",
    "\n",
    "    # 1. check if the predicted point is contained in some sense\n",
    "    spatial_df[\"contained\"] = spatial_df.apply(lambda row:\n",
    "                                               inside_sphere(spatial_params,\n",
    "                                                             row[['l0', 'alpha', 'l_i', 'beta_i', 'radius']]))\n",
    "\n",
    "    # 2. For those synsets, which is the nearest synset point\n",
    "    #use distance() to calculate distance between centers\n",
    "\n",
    "    # 3. If None of the synsets apply to that word sense\n",
    "    # use sphere_dist to find the nearest sphere (most general synset), and assign it to that synset\n",
    "    # (this maybe good for rare senses)\n",
    "\n",
    "\n",
    "    return synsets\n",
    "\n",
    "def train_loss(tmp_pred, synset_params):\n",
    "    # Loss is the distance between the two spheres/containment of the word within that sphere\n",
    "    # radius acts as tolerance!\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "TEXT = data.Field(use_vocab=True,\n",
    "                  lower=True)\n",
    "\n",
    "LABEL = data.Field(is_target=True,\n",
    "                   use_vocab=False,\n",
    "                   unk_token=None,\n",
    "                   sequential=False,\n",
    "                   postprocessing=data.Pipeline(\n",
    "                       lambda x: torch.tensor(list(map(float, removeBra(x).split(' '))),\n",
    "                                              dtype=torch.double)),\n",
    "                   dtype=torch.DoubleTensor)\n",
    "                        #data.Pipeline(lambda x: torch.tensor(x, dtype=torch.double)))\n",
    "\n",
    "# LABEL.numericalize()\n",
    "fields = [(\"text\",TEXT),(\"lemmatized_text\",TEXT), (None, None), (None,None), (None, None), (\"label\",LABEL)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train, valid, test = datasets.SequenceTaggingDataset.splits(path='../data/test_transformer/',\n",
    "                                   train = train_path,\n",
    "                                   validation = validate_path,\n",
    "                                   test = test_path,\n",
    "                                   fields=[(\"text\",TEXT),(\"lemmatized_text\",TEXT), (None, None), (None,None), (None, None), (\"label\",LABEL)]) #,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using pre-trained word embeddings.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "use_pretrained = True\n",
    "if use_pretrained:\n",
    "    print('We are using pre-trained word embeddings.')\n",
    "    TEXT.build_vocab(train, vectors=\"glove.840B.300d\")\n",
    "else:\n",
    "    print('We are training word embeddings from scratch.')\n",
    "    TEXT.build_vocab(train, max_size=5000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified Field dtype <class 'torch.DoubleTensor'> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5760/4265054335.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# LABEL.build_vocab(train.label)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mLABEL\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumericalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mnumericalize\u001B[1;34m(self, arr, device)\u001B[0m\n\u001B[0;32m    340\u001B[0m                     \u001B[1;34m\"use_vocab=False because we do not know how to numericalize it. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m                     \u001B[1;34m\"Please raise an issue at \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 342\u001B[1;33m                     \"https://github.com/pytorch/text/issues\".format(self.dtype))\n\u001B[0m\u001B[0;32m    343\u001B[0m             \u001B[0mnumericalization_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;31m# It doesn't make sense to explicitly coerce to a numeric type if\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Specified Field dtype <class 'torch.DoubleTensor'> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues"
     ]
    }
   ],
   "source": [
    "# LABEL.build_vocab(train.label)\n",
    "LABEL.numericalize(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified Field dtype <class 'torch.DoubleTensor'> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5760/4150467061.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m                                                         sort=True)\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_iterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Numericalize premises:\\n\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Entailment labels:\\n\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\iterator.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    158\u001B[0m                     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m                         \u001B[0mminibatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort_key\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreverse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m                 \u001B[1;32myield\u001B[0m \u001B[0mBatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mminibatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, dataset, device)\u001B[0m\n\u001B[0;32m     32\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mfield\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m                     \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m                     \u001B[0msetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mprocess\u001B[1;34m(self, batch, device)\u001B[0m\n\u001B[0;32m    229\u001B[0m         \"\"\"\n\u001B[0;32m    230\u001B[0m         \u001B[0mpadded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m         \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumericalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpadded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mnumericalize\u001B[1;34m(self, arr, device)\u001B[0m\n\u001B[0;32m    340\u001B[0m                     \u001B[1;34m\"use_vocab=False because we do not know how to numericalize it. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m                     \u001B[1;34m\"Please raise an issue at \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 342\u001B[1;33m                     \"https://github.com/pytorch/text/issues\".format(self.dtype))\n\u001B[0m\u001B[0;32m    343\u001B[0m             \u001B[0mnumericalization_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;31m# It doesn't make sense to explicitly coerce to a numeric type if\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Specified Field dtype <class 'torch.DoubleTensor'> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues"
     ]
    }
   ],
   "source": [
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "                                                        (train, valid),\n",
    "                                                        device=DEVICE,\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                        sort_key=lambda x: len(x.text),\n",
    "                                                        repeat=False,\n",
    "                                                        sort=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified Field dtype <class 'torch.DoubleTensor'> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5760/1354259130.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_iterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Numericalize premises:\\n\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Entailment labels:\\n\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\iterator.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    158\u001B[0m                     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m                         \u001B[0mminibatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort_key\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreverse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m                 \u001B[1;32myield\u001B[0m \u001B[0mBatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mminibatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, dataset, device)\u001B[0m\n\u001B[0;32m     32\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mfield\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m                     \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m                     \u001B[0msetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mprocess\u001B[1;34m(self, batch, device)\u001B[0m\n\u001B[0;32m    229\u001B[0m         \"\"\"\n\u001B[0;32m    230\u001B[0m         \u001B[0mpadded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m         \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumericalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpadded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\anaconda3\\envs\\ball4wsd\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001B[0m in \u001B[0;36mnumericalize\u001B[1;34m(self, arr, device)\u001B[0m\n\u001B[0;32m    340\u001B[0m                     \u001B[1;34m\"use_vocab=False because we do not know how to numericalize it. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m                     \u001B[1;34m\"Please raise an issue at \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 342\u001B[1;33m                     \"https://github.com/pytorch/text/issues\".format(self.dtype))\n\u001B[0m\u001B[0;32m    343\u001B[0m             \u001B[0mnumericalization_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;31m# It doesn't make sense to explicitly coerce to a numeric type if\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Specified Field dtype <class 'torch.DoubleTensor'> can not be used with use_vocab=False because we do not know how to numericalize it. Please raise an issue at https://github.com/pytorch/text/issues"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iterator))\n",
    "print(\"Numericalize premises:\\n\", batch.text)\n",
    "print(\"Entailment labels:\\n\", batch.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}