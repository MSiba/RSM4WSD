{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import math\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('seaborn')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# To ensure that the code is reproducible, set random seeds\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        token      stemm  pos     annotation          synset  \\\n0      having       have    v  no-annotation       no-synset   \n1         the        the  NaN  no-annotation       no-synset   \n2   necessary  necessary    a     01580050-a  necessary.a.01   \n3       means      means    n     00172710-n      means.n.01   \n4          or         or  NaN  no-annotation       no-synset   \n5       skill      skill    n  no-annotation       no-synset   \n6          or         or  NaN  no-annotation       no-synset   \n7    know-how   know-how    n     05616786-n   know-how.n.01   \n8          or         or  NaN  no-annotation       no-synset   \n9   authority  authority    n     05196582-n  authority.n.01   \n10         to         to  NaN  no-annotation       no-synset   \n11         do         do    v  no-annotation       no-synset   \n12  something  something  NaN  no-annotation       no-synset   \n13        not        not    r     00024073-r        not.r.01   \n14     having       have    v  no-annotation       no-synset   \n15        the        the  NaN  no-annotation       no-synset   \n16  necessary  necessary    a     01580050-a  necessary.a.01   \n17      means      means    n     00172710-n      means.n.01   \n18         or         or  NaN  no-annotation       no-synset   \n19      skill      skill    n  no-annotation       no-synset   \n\n                                     tag  \n0                                      O  \n1                                      O  \n2     [135144.0 25.01 64176.03 90.0 0.5]  \n3      [111736.0 98.31 98012.7 0.0 18.5]  \n4                                      O  \n5                                      O  \n6                                      O  \n7   [142676.0 107.17 71890.08 0.0 106.5]  \n8                                      O  \n9     [37587.0 104.34 194973.98 0.0 7.5]  \n10                                     O  \n11                                     O  \n12                                     O  \n13    [129433.0 178.71 20604.94 0.0 0.5]  \n14                                     O  \n15                                     O  \n16    [135144.0 25.01 64176.03 90.0 0.5]  \n17     [111736.0 98.31 98012.7 0.0 18.5]  \n18                                     O  \n19                                     O  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>stemm</th>\n      <th>pos</th>\n      <th>annotation</th>\n      <th>synset</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>having</td>\n      <td>have</td>\n      <td>v</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the</td>\n      <td>the</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>necessary</td>\n      <td>necessary</td>\n      <td>a</td>\n      <td>01580050-a</td>\n      <td>necessary.a.01</td>\n      <td>[135144.0 25.01 64176.03 90.0 0.5]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>means</td>\n      <td>means</td>\n      <td>n</td>\n      <td>00172710-n</td>\n      <td>means.n.01</td>\n      <td>[111736.0 98.31 98012.7 0.0 18.5]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>skill</td>\n      <td>skill</td>\n      <td>n</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>know-how</td>\n      <td>know-how</td>\n      <td>n</td>\n      <td>05616786-n</td>\n      <td>know-how.n.01</td>\n      <td>[142676.0 107.17 71890.08 0.0 106.5]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>authority</td>\n      <td>authority</td>\n      <td>n</td>\n      <td>05196582-n</td>\n      <td>authority.n.01</td>\n      <td>[37587.0 104.34 194973.98 0.0 7.5]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>to</td>\n      <td>to</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>do</td>\n      <td>do</td>\n      <td>v</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>something</td>\n      <td>something</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>not</td>\n      <td>not</td>\n      <td>r</td>\n      <td>00024073-r</td>\n      <td>not.r.01</td>\n      <td>[129433.0 178.71 20604.94 0.0 0.5]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>having</td>\n      <td>have</td>\n      <td>v</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>the</td>\n      <td>the</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>necessary</td>\n      <td>necessary</td>\n      <td>a</td>\n      <td>01580050-a</td>\n      <td>necessary.a.01</td>\n      <td>[135144.0 25.01 64176.03 90.0 0.5]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>means</td>\n      <td>means</td>\n      <td>n</td>\n      <td>00172710-n</td>\n      <td>means.n.01</td>\n      <td>[111736.0 98.31 98012.7 0.0 18.5]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>or</td>\n      <td>or</td>\n      <td>NaN</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>skill</td>\n      <td>skill</td>\n      <td>n</td>\n      <td>no-annotation</td>\n      <td>no-synset</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pwngc_path = \"../data/test_transformer/pwngc4torchtext.csv\"\n",
    "pwngc_df = pd.read_csv(pwngc_path, delimiter=\"\\t\", header=None)\n",
    "pwngc_df.columns = [\"token\", \"stemm\", \"pos\", \"annotation\", \"synset\", \"tag\" ]\n",
    "pwngc_df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "len(np.where(pwngc_df[\"tag\"] != 'O')[0])\n",
    "# 532.821 annotated tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135144.0 25.01 64176.03 90.0 0.5]\n",
      "<class 'str'>\n",
      "tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "tag2 = pwngc_df['tag'][2]\n",
    "print(tag2)\n",
    "print(type(tag2))\n",
    "def removeBra(string_list):\n",
    "    if string_list[0] == \"[\" and string_list[-1] == \"]\":\n",
    "        return string_list[1:-1]\n",
    "    else:\n",
    "        return string_list\n",
    "\n",
    "tag2list = torch.tensor(list(map(float, removeBra(tag2).split(' '))), dtype=torch.float32)\n",
    "# tag2list = ast.literal_eval(tag2)\n",
    "print(tag2list)\n",
    "print(type(tag2list))\n",
    "# type(eval(\"tensor({}, device='{}')\".format(tag2, \"cpu\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# split the dataset into training, validation and testing\n",
    "train_path = \"train.csv\"\n",
    "validate_path = \"validate.csv\"\n",
    "test_path = \"test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def read_data(corpus_file, datafields):\n",
    "    \"\"\"\n",
    "    reads the stem word and the spatial tag of each token in the .csv file\n",
    "    :param corpus_file:\n",
    "    :param datafields:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        examples = []\n",
    "        words = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                examples.append(data.Example.fromlist([words, labels], datafields))\n",
    "                words = []\n",
    "                labels = []\n",
    "            else:\n",
    "                columns = line.split()\n",
    "                words.append(columns[1])\n",
    "                labels.append(columns[-1])\n",
    "        return data.Dataset(examples, datafields)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#   train_examples = read_data(\"../data/test_transformer/train.csv\", self.fields) #'data/eng.train.iob', self.fields)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "TEXT = data.Field(use_vocab=False,\n",
    "                  lower=True)\n",
    "\n",
    "LABEL = data.Field(is_target=True,\n",
    "                   use_vocab=False,\n",
    "                   unk_token=None,\n",
    "                   preprocessing=data.Pipeline(lambda x: torch.tensor(list(map(float, removeBra(x).split(' '))), dtype=torch.double)),\n",
    "                   dtype=data.Pipeline(lambda x: torch.tensor(x, dtype=torch.double)))\n",
    "\n",
    "train, valid, test = datasets.SequenceTaggingDataset.splits(path='../data/test_transformer/',\n",
    "                                   train = train_path,\n",
    "                                   validation = validate_path,\n",
    "                                   test = test_path,\n",
    "                                   fields=[(\"text\",TEXT),(\"lemmatized_text\",TEXT), (None, None), (None,None), (None, None), (\"label\",LABEL)]) #,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['having', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how', 'or', 'authority', 'to', 'do', 'something'] ['have', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how', 'or', 'authority', 'to', 'do', 'something'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1174e+05, 9.8310e+01, 9.8013e+04, 0.0000e+00, 1.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4268e+05, 1.0717e+02, 7.1890e+04, 0.0000e+00, 1.0650e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([3.7587e+04, 1.0434e+02, 1.9497e+05, 0.0000e+00, 7.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['not', 'having', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how'] ['not', 'have', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1174e+05, 9.8310e+01, 9.8013e+04, 0.0000e+00, 1.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4268e+05, 1.0717e+02, 7.1890e+04, 0.0000e+00, 1.0650e+02],\n",
      "       dtype=torch.float64)]\n",
      "['having', 'or', 'being', 'more', 'than', 'normal', 'or', 'necessary', ':'] ['have', 'or', 'be', 'many%3|more%3|much%3|more%4|much%4', 'than', 'normal', 'or', 'necessary', ':'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2872e+05, 2.0550e+01, 5.4535e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['involving', 'deductive_reasoning', 'from', 'a', 'general', 'principle', 'to', 'a', 'necessary', 'effect'] ['involve', 'deductive_reasoning', 'from', 'a', 'general', 'principle', 'to', 'a', 'necessary', 'effect'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([4.9319e+04, 1.0515e+02, 1.6306e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.1143e+05, 3.0800e+01, 8.3244e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1814e+05, 1.0754e+02, 9.5664e+04, 0.0000e+00, 1.4500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['not', 'supported', 'by', 'fact'] ['not', 'support', 'by', 'fact'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.4906e+04, 1.0194e+02, 1.1614e+05, 1.8000e+02, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['not', 'supported', 'by', 'fact'] ['not', 'support', 'by', 'fact'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.4906e+04, 1.0194e+02, 1.1483e+05, 1.8000e+02, 2.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['lacking', 'necessary', 'physical', 'or', 'mental_ability'] ['lack', 'necessary', 'physical_ability', 'or', 'mental_ability'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([5.1520e+03, 1.1805e+02, 2.2714e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.6015e+04, 1.0743e+02, 1.2885e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['the', 'necessary', 'consequences', 'of', \"one's\", 'actions'] ['the', 'necessary', 'consequence', 'of', 'one', 'action'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 7.6603e+04, 9.5740e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['having', 'every', 'necessary', 'or', 'normal', 'part', 'or', 'component', 'or', 'step'] ['have', 'every', 'necessary', 'or', 'normal', 'part', 'or', 'component', 'or', 'step'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2872e+05, 2.0550e+01, 5.4535e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['having', 'or', 'displaying', 'all', 'the', 'characteristics', 'necessary', 'for', 'completeness'] ['have', 'or', 'display', 'all', 'the', 'characteristic', 'necessary', 'for', 'completeness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.0349e+04, 1.0389e+02, 1.6340e+05, 0.0000e+00, 2.4500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.6165e+04, 1.1673e+02, 2.1134e+05, 0.0000e+00, 3.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['having', 'or', 'displaying', 'all', 'the', 'characteristics', 'necessary', 'for', 'completeness'] ['have', 'or', 'display', 'all', 'the', 'characteristic', 'necessary', 'for', 'completeness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.0349e+04, 1.0389e+02, 1.8358e+05, 0.0000e+00, 3.9500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.6165e+04, 1.1673e+02, 2.1134e+05, 0.0000e+00, 3.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['(', 'of', 'a', 'boat', 'or', 'vessel', ')', 'furnished', 'with', 'necessary', 'official_documents', 'specifying', 'ownership', 'etc'] ['(', 'of', 'a', 'boat', 'or', 'vessel', ')', 'furnished', 'with', 'necessary', 'official_document', 'specify', 'ownership', 'etc.'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([3.4035e+04, 7.8060e+01, 1.7478e+05, 0.0000e+00, 6.4500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.9658e+04, 7.3010e+01, 1.3975e+05, 0.0000e+00, 1.8950e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([7.7181e+04, 1.1327e+02, 1.4597e+05, 0.0000e+00, 2.8850e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.2580e+03, 1.0677e+02, 2.2125e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.7896e+04, 1.7910e+02, 6.2122e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['lacking', 'necessary', 'documents', '(', 'as', 'for', 'e.g.', 'permission', 'to', 'live', 'or', 'work', 'in', 'a', 'country', ')'] ['lack', 'necessary', 'document', '(', 'as', 'for', 'e.g.', 'permission', 'to', 'live', 'or', 'work', 'in', 'a', 'country', ')'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([6.4798e+04, 1.0888e+02, 1.5864e+05, 0.0000e+00, 3.9050e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.6105e+04, 1.7943e+02, 8.3903e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.5885e+04, 1.0822e+02, 1.6395e+05, 0.0000e+00, 1.3500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4370e+03, 9.3970e+01, 2.0489e+05, 0.0000e+00, 2.2750e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['lacking', 'necessary', 'force', 'for', 'effectiveness'] ['lack', 'necessary', 'force', 'for', 'effectiveness'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3004e+05, 1.1761e+02, 1.0131e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['using', 'the', 'minimum', 'of', 'time', 'or', 'resources', 'necessary', 'for', 'effectiveness'] ['use', 'the', 'minimum', 'of', 'time', 'or', 'resource', 'necessary', 'for', 'effectiveness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.8864e+04, 7.5350e+01, 1.4785e+05, 5.3130e+01, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.8408e+04, 1.0795e+02, 1.8866e+05, 0.0000e+00, 1.2500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3004e+05, 1.1761e+02, 1.0131e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['possible', 'but', 'not', 'necessary'] ['possible', 'but', 'not', 'necessary'] [tensor([8.5479e+04, 6.0380e+01, 1.2985e+05, 9.5740e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['left', 'to', 'personal', 'choice'] ['leave', 'to', 'personal', 'choice'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([2.7140e+04, 1.9770e+01, 1.2471e+05, 2.5840e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.4028e+05, 7.7850e+01, 1.0613e+05, 6.0000e+01, 5.9500e+01],\n",
      "       dtype=torch.float64)]\n",
      "['morally', 'binding', 'or', 'necessary'] ['morally', 'bind', 'or', 'necessary'] [tensor([2.4772e+04, 1.7990e+02, 1.2524e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['urgently', 'needed'] ['urgently', 'need'] [tensor([2.6208e+04, 1.7894e+02, 1.2382e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.9570e+03, 1.0177e+02, 7.9864e+04, 1.8000e+02, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['absolutely', 'necessary'] ['absolutely', 'necessary'] [tensor([8.1604e+04, 1.7865e+02, 6.8438e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['fitted', 'or', 'equipped', 'with', 'necessary', 'rigging', '(', 'sails', 'and', 'shrouds', 'and', 'stays', 'etc', ')'] ['fit', 'or', 'equip', 'with', 'necessary', 'rigging', '(', 'sail', 'and', 'shroud', 'and', 'stays', 'etc.', ')'] [tensor([1.2442e+05, 4.6020e+01, 1.8016e+05, 1.8000e+02, 2.6500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4270e+05, 9.0190e+01, 7.2764e+04, 1.8000e+02, 2.6500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.7251e+04, 8.1770e+01, 1.2355e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.9339e+04, 7.0330e+01, 1.5216e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.7896e+04, 1.7910e+02, 6.2122e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for t, lt, l in zip(train.text, train.lemmatized_text, train.label):\n",
    "    print(t, lt, l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using pre-trained word embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained embeddings that come with the torchtext library.\n",
    "use_pretrained = True\n",
    "if use_pretrained:\n",
    "    print('We are using pre-trained word embeddings.')\n",
    "    TEXT.build_vocab(train, vectors=\"glove.840B.300d\")\n",
    "else:\n",
    "    print('We are training word embeddings from scratch.')\n",
    "    TEXT.build_vocab(train, max_size=5000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1., dtype=torch.float64)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.tensor(1, dtype=torch.float)\n",
    "tens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "x = [13.4, 34.4, 2.0]\n",
    "tens = torch.tensor(x, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([13.4000, 34.4000,  2.0000], dtype=torch.float64)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([13.4000, 34.4000,  2.0000], dtype=torch.float64)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tend = torch.tensor(x, dtype=torch.double)\n",
    "tend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    repeat=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lacking', 'necessary', 'force', 'for', 'effectiveness'] ['lack', 'necessary', 'force', 'for', 'effectiveness'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3004e+05, 1.1761e+02, 1.0131e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['lacking', 'necessary', 'documents', '(', 'as', 'for', 'e.g.', 'permission', 'to', 'live', 'or', 'work', 'in', 'a', 'country', ')'] ['lack', 'necessary', 'document', '(', 'as', 'for', 'e.g.', 'permission', 'to', 'live', 'or', 'work', 'in', 'a', 'country', ')'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([6.4798e+04, 1.0888e+02, 1.5864e+05, 0.0000e+00, 3.9050e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.6105e+04, 1.7943e+02, 8.3903e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.5885e+04, 1.0822e+02, 1.6395e+05, 0.0000e+00, 1.3500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4370e+03, 9.3970e+01, 2.0489e+05, 0.0000e+00, 2.2750e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['having', 'or', 'displaying', 'all', 'the', 'characteristics', 'necessary', 'for', 'completeness'] ['have', 'or', 'display', 'all', 'the', 'characteristic', 'necessary', 'for', 'completeness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.0349e+04, 1.0389e+02, 1.8358e+05, 0.0000e+00, 3.9500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.6165e+04, 1.1673e+02, 2.1134e+05, 0.0000e+00, 3.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['lacking', 'necessary', 'physical', 'or', 'mental_ability'] ['lack', 'necessary', 'physical_ability', 'or', 'mental_ability'] [tensor([6.0597e+04, 1.2401e+02, 1.2927e+05, 1.8000e+02, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([5.1520e+03, 1.1805e+02, 2.2714e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.6015e+04, 1.0743e+02, 1.2885e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['absolutely', 'necessary'] ['absolutely', 'necessary'] [tensor([8.1604e+04, 1.7865e+02, 6.8438e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['having', 'every', 'necessary', 'or', 'normal', 'part', 'or', 'component', 'or', 'step'] ['have', 'every', 'necessary', 'or', 'normal', 'part', 'or', 'component', 'or', 'step'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2872e+05, 2.0550e+01, 5.4535e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['possible', 'but', 'not', 'necessary'] ['possible', 'but', 'not', 'necessary'] [tensor([8.5479e+04, 6.0380e+01, 1.2985e+05, 9.5740e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['urgently', 'needed'] ['urgently', 'need'] [tensor([2.6208e+04, 1.7894e+02, 1.2382e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.9570e+03, 1.0177e+02, 7.9864e+04, 1.8000e+02, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['not', 'supported', 'by', 'fact'] ['not', 'support', 'by', 'fact'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.4906e+04, 1.0194e+02, 1.1614e+05, 1.8000e+02, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['morally', 'binding', 'or', 'necessary'] ['morally', 'bind', 'or', 'necessary'] [tensor([2.4772e+04, 1.7990e+02, 1.2524e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['not', 'supported', 'by', 'fact'] ['not', 'support', 'by', 'fact'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([4.4906e+04, 1.0194e+02, 1.1483e+05, 1.8000e+02, 2.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['having', 'or', 'displaying', 'all', 'the', 'characteristics', 'necessary', 'for', 'completeness'] ['have', 'or', 'display', 'all', 'the', 'characteristic', 'necessary', 'for', 'completeness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.0349e+04, 1.0389e+02, 1.6340e+05, 0.0000e+00, 2.4500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.6165e+04, 1.1673e+02, 2.1134e+05, 0.0000e+00, 3.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['having', 'or', 'being', 'more', 'than', 'normal', 'or', 'necessary', ':'] ['have', 'or', 'be', 'many%3|more%3|much%3|more%4|much%4', 'than', 'normal', 'or', 'necessary', ':'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.2872e+05, 2.0550e+01, 5.4535e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['not', 'having', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how'] ['not', 'have', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how'] [tensor([1.2943e+05, 1.7871e+02, 2.0605e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1174e+05, 9.8310e+01, 9.8013e+04, 0.0000e+00, 1.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4268e+05, 1.0717e+02, 7.1890e+04, 0.0000e+00, 1.0650e+02],\n",
      "       dtype=torch.float64)]\n",
      "['(', 'of', 'a', 'boat', 'or', 'vessel', ')', 'furnished', 'with', 'necessary', 'official_documents', 'specifying', 'ownership', 'etc'] ['(', 'of', 'a', 'boat', 'or', 'vessel', ')', 'furnished', 'with', 'necessary', 'official_document', 'specify', 'ownership', 'etc.'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([3.4035e+04, 7.8060e+01, 1.7478e+05, 0.0000e+00, 6.4500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.9658e+04, 7.3010e+01, 1.3975e+05, 0.0000e+00, 1.8950e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([7.7181e+04, 1.1327e+02, 1.4597e+05, 0.0000e+00, 2.8850e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([6.2580e+03, 1.0677e+02, 2.2125e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.7896e+04, 1.7910e+02, 6.2122e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64)]\n",
      "['using', 'the', 'minimum', 'of', 'time', 'or', 'resources', 'necessary', 'for', 'effectiveness'] ['use', 'the', 'minimum', 'of', 'time', 'or', 'resource', 'necessary', 'for', 'effectiveness'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.8864e+04, 7.5350e+01, 1.4785e+05, 5.3130e+01, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.8408e+04, 1.0795e+02, 1.8866e+05, 0.0000e+00, 1.2500e+01],\n",
      "       dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3004e+05, 1.1761e+02, 1.0131e+05, 0.0000e+00, 2.5000e+00],\n",
      "       dtype=torch.float64)]\n",
      "['fitted', 'or', 'equipped', 'with', 'necessary', 'rigging', '(', 'sails', 'and', 'shrouds', 'and', 'stays', 'etc', ')'] ['fit', 'or', 'equip', 'with', 'necessary', 'rigging', '(', 'sail', 'and', 'shroud', 'and', 'stays', 'etc.', ')'] [tensor([1.2442e+05, 4.6020e+01, 1.8016e+05, 1.8000e+02, 2.6500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4270e+05, 9.0190e+01, 7.2764e+04, 1.8000e+02, 2.6500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([8.7251e+04, 8.1770e+01, 1.2355e+05, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([5.9339e+04, 7.0330e+01, 1.5216e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([8.7896e+04, 1.7910e+02, 6.2122e+04, 0.0000e+00, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['involving', 'deductive_reasoning', 'from', 'a', 'general', 'principle', 'to', 'a', 'necessary', 'effect'] ['involve', 'deductive_reasoning', 'from', 'a', 'general', 'principle', 'to', 'a', 'necessary', 'effect'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([4.9319e+04, 1.0515e+02, 1.6306e+05, 0.0000e+00, 1.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.1143e+05, 3.0800e+01, 8.3244e+04, 7.8460e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1814e+05, 1.0754e+02, 9.5664e+04, 0.0000e+00, 1.4500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['the', 'necessary', 'consequences', 'of', \"one's\", 'actions'] ['the', 'necessary', 'consequence', 'of', 'one', 'action'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 7.6603e+04, 9.5740e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n",
      "['left', 'to', 'personal', 'choice'] ['leave', 'to', 'personal', 'choice'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([2.7140e+04, 1.9770e+01, 1.2471e+05, 2.5840e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.4028e+05, 7.7850e+01, 1.0613e+05, 6.0000e+01, 5.9500e+01],\n",
      "       dtype=torch.float64)]\n",
      "['having', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how', 'or', 'authority', 'to', 'do', 'something'] ['have', 'the', 'necessary', 'means', 'or', 'skill', 'or', 'know-how', 'or', 'authority', 'to', 'do', 'something'] [tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01],\n",
      "       dtype=torch.float64), tensor([1.1174e+05, 9.8310e+01, 9.8013e+04, 0.0000e+00, 1.8500e+01],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([1.4268e+05, 1.0717e+02, 7.1890e+04, 0.0000e+00, 1.0650e+02],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([3.7587e+04, 1.0434e+02, 1.9497e+05, 0.0000e+00, 7.5000e+00],\n",
      "       dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0.], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator.data():\n",
    "    print(batch.text, batch.lemmatized_text, batch.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}