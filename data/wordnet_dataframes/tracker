In this file, I keep record of each data file to track the process of creating datasets, as those datasets can be
adjusted in future experiments.

# 1. Graph data
*wordnet_nouns.gpickle*: graph of nouns extracted from the hypernym-hyponym hierarchy of WordNet
*wordnet_verbs.gpickle*: graph of WordNet verbs
*wordnet_adjectives.gpickle*: graph of WordNet adjectives
*wordnet_adverbs.gpickle*: graph of WordNet adverbs
Created in script: embedding_space/wn2graph.py
Used in scripts: embedding_space/mptt.py

# 2. DFS Traversal using mptt into Dataframe
*NOUNS.pickle*: dataframe containing the start and end of each synset in the hierarchy
*VERBS.pickle*
*ADJECTIVES.pickle*
*ADVERBS.pickle*
Created in script: embedding_space/mptt.py
Used in scripts: embedding_space/{nouns_dataset; verbs_dataset; adjectives_dataset; adverbs_dataset}

# 3. Engineering of the hierarchies in space (shifting/rotating)
*nouns_df.pickle*: dataframe containing new coordinates of the senses, as well as more adding
dimensionality (current:2D)
*verbs_df.pickle*
*adjectives_df.pickle*
*adverbs_df.pickle*
Created in scripts: embedding_space/{nouns_dataset; verbs_dataset; adjectives_dataset; adverbs_dataset}
Used in script: embedding_space/merge_datasets.py

# 4. Merged all datasets into One Big Dataset of 117.000+ WordNet Synsets
*spatial_wordnet_df*: dataframe of nouns, verbs, adjectives, and adverbs.
Created in script: embedding_space/merge_datasets.py
Used in script: embedding_space/spatial_datasets.py

# 5. Create a Dataframe for WordNet words, and their relations to their synsets
*word_mapping_df.pickle*: dataframe mapping each wn.word into its [senses], word coordinates wrt. senses, and alpha.
*exploded_word_mapping.pickle*: dataframe which explodes the previous one to represent each sense in a single column.
*exploded_word_mapping_POS.pickle*: dataframe with POS added
Created in script: embedding_space/spatial_datasets.py
Used in script:

